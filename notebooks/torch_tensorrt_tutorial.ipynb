{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ae353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a96f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by defining a model\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        x_out = self.relu(x)\n",
    "        y_out = self.relu(y)\n",
    "        x_y_out = x_out + y_out\n",
    "        return torch.mean(x_y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e90771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample float inputs and initialize model\n",
    "sample_inputs = [torch.rand((5, 7)).cuda(), torch.rand((5, 7)).cuda()]\n",
    "model = Model().eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we compile the model using torch.compile\n",
    "# For the default settings, we can simply call torch.compile\n",
    "# with the backend \"torch_tensorrt\", and run the model on an\n",
    "# input to cause compilation, as so:\n",
    "optimized_model = torch.compile(model, backend=\"torch_tensorrt\", dynamic=False)\n",
    "optimized_model(*sample_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c9da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we use Torch utilities to clean up the workspace\n",
    "# after the previous compile invocation\n",
    "torch._dynamo.reset()\n",
    "\n",
    "# Define sample half inputs and initialize model\n",
    "sample_inputs_half = [\n",
    "    torch.rand((5, 7)).half().cuda(),\n",
    "    torch.rand((5, 7)).half().cuda(),\n",
    "]\n",
    "model_half = Model().eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cce0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to customize certain options in the backend,\n",
    "# but still use the torch.compile call directly, we can provide\n",
    "# custom options to the backend via the \"options\" keyword\n",
    "# which takes in a dictionary mapping options to values.\n",
    "#\n",
    "# For accepted backend options, see the CompilationSettings dataclass:\n",
    "# py/torch_tensorrt/dynamo/_settings.py\n",
    "backend_kwargs = {\n",
    "    \"enabled_precisions\": {torch.half},\n",
    "    \"debug\": True,\n",
    "    \"min_block_size\": 2,\n",
    "    \"torch_executed_ops\": {\"torch.ops.aten.sub.Tensor\"},\n",
    "    \"optimization_level\": 4,\n",
    "    \"use_python_runtime\": False,\n",
    "}\n",
    "\n",
    "# Run the model on an input to cause compilation, as so:\n",
    "optimized_model_custom = torch.compile(\n",
    "    model_half,\n",
    "    backend=\"torch_tensorrt\",\n",
    "    options=backend_kwargs,\n",
    "    dynamic=False,\n",
    ")\n",
    "optimized_model_custom(*sample_inputs_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44003dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we use Torch utilities to clean up the workspace\n",
    "torch._dynamo.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2a6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mmcv]",
   "language": "python",
   "name": "conda-env-mmcv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
